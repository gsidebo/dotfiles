PATH="/Library/Frameworks/Python.framework/Versions/2.7/bin:/Applications/Postgres.app/Contents/Versions/9.6/bin:${PATH}:/usr/local/mysql/bin"
# Remove duplicates from PATH
PATH=$(echo "$PATH" | awk -v RS=':' -v ORS=":" '!a[$1]++' | sed 's/:$//' | tr -d '\n')
export PATH

# Init pyenv and pyenv-virtualenv on shell startup
eval "$(pyenv init -)"
eval "$(pyenv virtualenv-init -)"

### Virtualenv settings
export VIRTUALENV_PYTHON=/usr/local/bin/python3
export VIRTUALENVWRAPPER_PYTHON=$VIRTUALENV_PYTHON
export VIRTUALENVWRAP_SH_PATH="/usr/local/bin/virtualenvwrapper.sh"
export VIRTUALENVWRAPPER_SCRIPT=/usr/local/bin/virtualenvwrapper.sh
export WORKON_HOME=$HOME/.virtualenvs
export PROJECT_HOME=$DEVPATH
### UNCOMMENT TO INITIALIZE VIRTUALENV ON SHELL STARTUP
# source "$VIRTUALENVWRAP_SH_PATH"

export EDITOR="/usr/local/bin/mate -w"
export SCREENSHOTS='/Users/gavin/Screenshots'
export CODESNIP='/Users/gavin/Code Snippets'
export SNIP=$CODESNIP
export DBBACKUPDIR='/Users/gavin/Code Snippets/dbbackup'

export MM_PATH="$DEVPATH/micromasters"
export BOOTCAMP_PATH="$DEVPATH/bootcamp-ecommerce"
export SANDBOX_PATH="$DEVPATH/sandbox"
export SANDBOXBASH_PATH="$SANDBOX_PATH/bash"
export OPDISC_PATH="$DEVPATH/open-discussions"
export OVS_PATH="$DEVPATH/odl-video-service"
export XPRO_PATH="$DEVPATH/mitxpro"
export EDX_DOCKER_PATH="$DEVPATH/edx_devstack_docker/devstack"
export EDX_DOCKER_SRC_PATH="$DEVPATH/edx_devstack_docker/edx-platform"
export EDX_FICUS_PATH="$DEVPATH/edx_devstack_ficus"
export EDX_GINKGO_PATH="$DEVPATH/edx_devstack_ginkgo"
export DEVSTACK_TOOLS_PATH="$DEVPATH/custom_docker/odl_devstack_tools"
export RAPID_RESPONSE_PATH="$DEVPATH/rapid-response-xblock"
export RDEVPATH="$HOME/devreddit"
export REDDIT_CONF_PATH="$RDEVPATH/reddit-config"
export REDDIT_PATH="$RDEVPATH/reddit"
export XQUEUE_DOCKER_PATH="$DEVPATH/mitodlfork/xqueue-docker/"
export XQUEUE_VAGRANT_PATH="$DEVPATH/mitodlfork/xqueue-vagrant/"
export XQUEUE_EDX_VAGRANT_PATH="$DEVPATH/xqueue-vagrant/"
export XQUEUE_WATCHER_CFG_PATH="$DEVPATH/mitodlfork/xqueue-watcher-docker/"
export XQUEUE_WATCHER_SRC_PATH="$DEVPATH/mitodlfork/xqueue-watcher-docker/xqueue-watcher/"
export SALTSTACK_SANDBOX_PATH="$DEVPATH/salt-essentials-utils"
export OCW_STUDIO_PATH="$DEVPATH/ocw-studio"
export OCW_WWW_PATH="$DEVPATH/ocw-www"
export OCW_STARTER_PATH="$DEVPATH/ocw-course-hugo-starter"
export OCW_THEME_PATH="$DEVPATH/ocw-course-hugo-theme"
export BLANKIE_PATH="$DEVPATH/sideprojects/blankie"
alias cdmic="cd $MM_PATH"
alias cdm=cdmic
alias cdboot="cd $BOOTCAMP_PATH"
alias cdb=cdboot
alias cdsandbox="cd $SANDBOX_PATH"
alias cdsandboxbash="cd $SANDBOXBASH_PATH"
alias cdedxdock="cd $EDX_DOCKER_PATH"
alias cdedxsrc="cd $EDX_DOCKER_SRC_PATH"
alias cdedxf="cd $EDX_FICUS_PATH"
alias cdedxg="cd $EDX_GINKGO_PATH"
alias cdedx=cdedxdock
alias cdrapid="cd $RAPID_RESPONSE_PATH"
alias cdrdev="cd $RDEVPATH"
alias cdopdisc="cd $OPDISC_PATH"
alias cdo=cdopdisc
alias cdxpro="cd $XPRO_PATH"
alias cdx=cdxpro
alias cdredcon="cd $REDDIT_CONF_PATH"
alias cdovs="cd $OVS_PATH"
alias cdsalt="cd $DEVPATH/salt-ops"
alias cdxqueue="cd $XQUEUE_DOCKER_PATH"
alias cdxqueuevagrant="cd $XQUEUE_VAGRANT_PATH"
alias cdxqueueedxvagrant="cd $XQUEUE_EDX_VAGRANT_PATH"
alias cdxqueuewatch="cd $XQUEUE_WATCHER_CFG_PATH"
alias cdxqueuewatchsrc="cd $XQUEUE_WATCHER_SRC_PATH"
alias cdsaltsandbox="cd $SALTSTACK_SANDBOX_PATH"
alias cdocws="cd $OCW_STUDIO_PATH"
alias cdocww="cd $OCW_WWW_PATH"
alias cdocwstart="cd $OCW_STARTER_PATH"
alias cdocwt="cd $OCW_THEME_PATH"
alias cdside="cd $DEVPATH/sideprojects"
alias cdcli="cd $DEVPATH/sandbox/cli_commands"
alias cdblankie="cd $BLANKIE_PATH"

### Docker devstack settings
export CUSTOM_DEVSTACK_USE_YAML_CONFIG=1
export CUSTOM_DEVSTACK_IMG_NAME_PY2='edxops/edxapp:gavin'
export CUSTOM_DEVSTACK_IMG_NAME_PY3='edxops/edxapp:gavin-py3'
export CUSTOM_DEVSTACK_IMG_NAME=$CUSTOM_DEVSTACK_IMG_NAME_PY3
export CUSTOM_DEVSTACK_BASE_IMG_PY2='edxops/edxapp:latest'
# export CUSTOM_DEVSTACK_BASE_IMG_PY3='edxops/edxapp:juniper.master'
export CUSTOM_DEVSTACK_BASE_IMG_PY3='edxops/edxapp:latest'
export CUSTOM_DEVSTACK_BASE_IMG=$CUSTOM_DEVSTACK_BASE_IMG_PY3
export CUSTOM_DEVSTACK_PATH="/Users/gavin/dev/custom_docker/odl_devstack_tools"
export DEVSTACK_CONTAINER_BASE_DIR="/edx/app/edxapp"
export DEVSTACK_CONTAINER_HELPER_DIR="$DEVSTACK_CONTAINER_BASE_DIR/helper"
export DEVSTACK_CONTAINER_MOUNT_DIR="$DEVSTACK_CONTAINER_BASE_DIR/venvs/edxapp/src"
export COMPOSE_HTTP_TIMEOUT=6000
export USE_CUSTOM_DEVSTACK=1
export DEFAULT_CUSTOM_DEVSTACK_COMPOSE_FILE="docker-compose-custom.yml"
export EDX_SRC_PATH="$EDX_DOCKER_SRC_PATH"

### Assorted utilities
alias edit='charm'
alias f='open -a Finder ./' # Opens current directory in MacOS Finder
alias etchosts='sudo vim /etc/hosts'
alias fixenter="stty sane"
makegif() {
  palette="/tmp/palette.png"
  filters="fps=10,scale=600:-1:flags=bicubic"
  if (( $# < 2 )); then
    input="$1.mov"
	  output="$1.gif"
  else
    input="$1"
	output="$2"
  fi
  if [ ! -f "$input" ] ; then
    input_temp="/Users/gavin/Screenshots/$input"
	  output_temp="/Users/gavin/Screenshots/$output"
	  if [ -f "$input_temp" ]; then
	    input="$input_temp"
	    output="$output_temp"
  	fi
  fi
  ffmpeg -v warning -i "$input" -vf "$filters,palettegen" -y $palette
  ffmpeg -v warning -i "$input" -i $palette -lavfi "$filters [x]; [x][1:v] paletteuse" -y "$output"
}
snippet() {
  new_file_path="$CODESNIP"
  if [ ! -z "$2" ]; then
    new_file_path="$new_file_path/$1"
  fi
  cp "$1" "$new_file_path"
}
alias pastejson='pbpaste | jq .'
alias pastejsoncopy='pbpaste | jq . | pbcopy'
function ziptotar() {
  local basefilename=$1
  if [ -z $basefilename ] ; then
    echo "Need a base filename"
    return
  fi
  if [ -f "$basefilename.tar.gz" ] ; then
    echo "$basefilename.tar.gz already exists"
    return
  fi
  extract "$basefilename.zip"
  tar -czvf "$basefilename.tar.gz" $basefilename
  rm -rf "$basefilename/"
}
alias vboxprocesses="ps xao pid,command | grep 'VBox' | grep -v 'grep'"
pynbhere() {
  local existing_notebook=$(ls | grep '.ipynb')
  jupyter notebook $existing_notebook
}
alias pynb="cd $SANDBOX_PATH && pvenv; jupyter notebook --notebook-dir=$SANDBOX_PATH"
alias pynbopen="open http://localhost:8888"
alias ngrok="~/ngrok"

### Simple Git shortcuts
alias gchrelease='git checkout release'
alias gchrc='git checkout release-candidate'

### Git magic
export GITHUB_URL="https://github.com"
export GITHUB_API_URL="https://api.github.com"
export GITHUB_MIT_URL="https://github.mit.edu"
export GITHUB_MIT_API_URL="https://github.mit.edu/api/v3"
export GIT_AUTHOR_LABEL_NAME="Waiting on Author"
export GIT_REVIEW_LABEL_NAME="Needs Review"
gsetremote() {
  local mainbranch=$(gmainbranch)
  local branch=''
  if [ ! -z $1 ]; then
    branch="$1"
  else
    branch=$(gcurbranch)
  fi
  local git_remote=$(gbranchremote $branch)
  if [ -z "$git_remote" ]; then
    git_remote=$(git config "branch.$mainbranch.remote")
    if [ -z "$git_remote" ]; then
      echo "Couldn't determine a remote for current branch or master"
      exit 1
    else
      echo "Branch $branch has no remote. Defaulting to master remote ($remote)"
    fi
  fi
  echo "$git_remote"
}
gsetapivalues() {
  git_remote=$(gsetremote $1)
  remote_push_line=$(git remote -v | grep 'push' | grep "$git_remote")
  github_host=$(echo $remote_push_line | perl -nle '/[@|\/](github[\.\w]+)[\/|:]/ && print "$1";')
  if [[ $github_host == "github.mit.edu" ]]; then
    github_api_url=$GITHUB_MIT_API_URL
    github_token=$GITHUB_MIT_TOKEN
    github_url=$GITHUB_MIT_URL
  else
    github_api_url=$GITHUB_API_URL
    github_token=$GIT_TOKEN
    github_url=$GITHUB_URL
  fi
  remote_tail=$(echo $remote_push_line | perl -nle '/.*github[\.\w]+[\/|:]([^\/]+\/.*)\.git/ && print "$1";')
  github_owner=$(echo "$remote_tail" | grep -Eo '^[^\/]+')
  github_repo=$(echo "$remote_tail" | perl -nle '/\/(.*)$/ && print "$1";')
  if [ -z "$github_owner" ] || [ -z "$github_repo" ]; then
    echo "Could not properly set github_owner or github_repo."
  fi
}
"gh_api_call"() {
  if (( $# < 1 )); then
    echo "Need >= 1 param"
    return
  else
    api_url_stub="$1"; shift
  fi
  full_url="$github_api_url/$api_url_stub"
  curl -s -u "$GIT_USERNAME:$github_token" "$full_url" $@
}
gh_repos_api_call() {
  if (( $# < 1 )); then
    echo "Need >= 1 param"
    return
  else
    api_url_stub="$1"; shift
  fi
  gsetapivalues
  gh_api_call "repos/$github_owner/$github_repo/$api_url_stub" $@
}
gh_prs_api_call() {
  gsetapivalues
  api_url_stub="search/issues?q=repo:$github_owner/$github_repo+state:open+is:pr"
  if [ ! -z "$1" ]; then
    api_url_stub="$api_url_stub+$1"
  fi
  gh_api_call "$api_url_stub"
}
gh_pr_api_call() {
  gsetapivalues
  api_url_stub="pulls"
  #/repos/:owner/:repo/pulls/
}
gh_issue_api_call() {
  gsetapivalues
  if (( $# < 1 )); then
    echo "Need issue #"; return
  else
    issue_number="$1"; shift
	  api_url_stub="$github_api_url/repos/$github_owner/$github_repo/issues/$issue_number"
    if (( $# > 0 )); then
	  if [ '?' != $(echo "$1" | head -c 1) ]; then
	    api_url_stub="$api_url_stub/"
	  fi
	  api_url_stub="$api_url_stub$1"
	fi
  fi
  curl -s -u "$GIT_USERNAME:$github_token" "$api_url_stub"
  
}
gh_site_url_base() {
  gsetapivalues
  echo "$github_url/$github_owner/$github_repo"
}
gnewissue() {
  gsetapivalues
  open "$github_url/$github_owner/$github_repo/issues/new"
}
gcurbranchprinfo() {
  gsetapivalues
  local params=''
  if [ ! -z $1 ]; then
    params="&$1"
  fi
  curl -s -u "$GIT_USERNAME:$GIT_TOKEN" "$GITHUB_API_URL/repos/$github_owner/$github_repo/pulls?head=$github_owner:$(gcurbranch)$params"
}
gcurbranchprnumber() {
  gcurbranchprinfo | jq '.[0] | .number'
}
getissuefrombranch() {
  gcurbranch | grep -Eo '^[0-9]+'
}
gprissue() {
  if [ -z "$1" ]; then
    echo "Need PR issue # as param"
    return
  fi
  gh_repos_api_call "pulls/$1" | jq '.["body"]' | grep -Eo "[closes|Closes|fixes|Fixes]\s+\#\d+" | grep -Eo "\d+$"
}
gopenrepo() {
  gsetapivalues
  open $github_url/$github_owner/$github_repo
}
gopenpr() {
  gcurbranchprinfo | jq -r '.[0] | .["_links"]["html"]["href"]' | xargs open
}
gopenissue() {
  if [ -z "$1" ]; then
    # attempt to match numbers at the beginning of the branch name, which should indicate issue #
    issue=$(getissuefrombranch)
  else
    issue="$1"
  fi
  if [ -z "$issue" ]; then
    echo "No issue # specified"
  else
    gsetapivalues
    curl -s -u "$GIT_USERNAME:$GIT_TOKEN" "$GITHUB_API_URL/repos/$github_owner/$github_repo/issues/$issue" | jq -r '.["html_url"]' | xargs open
  fi
}
gopenprissue() {
  if [ -z "$1" ]; then
    pr_issue_number=$(gcurbranchprinfo | jq '.[0]["number"]')
  else
    pr_issue_number=$1
  fi
  gopenissue $(gprissue "$pr_issue_number")
}
gopencommit() {
  local urlbase=''
  if [ -z "$1" ]; then
    echo "Need commit SHA as param"
    return
  fi
  urlbase=$(gh_site_url_base)
  open "$urlbase/commit/$1"
}
gprbranchname() {
  if [ -z "$1" ]; then
    echo "Need PR issue # as param"
    return
  fi
  curl -s -u "$GIT_USERNAME:$GIT_TOKEN" "$GITHUB_API_URL/repos/$github_owner/$github_repo/pulls/$1" | jq -r '.["head"]["ref"]'
}
gchprbranch() {
  if [ -z "$1" ]; then
    echo "Need PR issue # as param"
    return
  fi
  gsetapivalues
  local branch_name=$(gprbranchname $1)
  git fetch && git checkout $branch_name
}
alias gchpr=gchprbranch
gprlabelset() {
  gsetapivalues
  if [ -z "$1" ]; then
    echo "Need label name as param"; return
  else
    label_to_add="$1"
  fi
  if [ -z "$2" ]; then
    issue_url=$(curl -s -u "$GIT_USERNAME:$GIT_TOKEN" "$GITHUB_API_URL/repos/$github_owner/$github_repo/pulls?head=$github_owner:$(gcurbranch)" | jq -r '.[0]["issue_url"]')
  else
    issue_url="$GITHUB_API_URL/repos/$github_owner/$github_repo/issues/$2"
  fi
  issue_labels_url="$issue_url/labels"
  curl -s -X PUT -u "$GIT_USERNAME:$GIT_TOKEN" "$issue_labels_url" -H "Content-Type: application/json" -d '["'"$label_to_add"'"]'
}
gprlabelreview() {
  gprlabelset "$GIT_REVIEW_LABEL_NAME" $1
}
alias gprlabelneeds=gprlabelreview
gprlabelwaiting() {
  gprlabelset "$GIT_AUTHOR_LABEL_NAME" $1
}
gprnew () {
  gsetapivalues
  local curbranch=$(gcurbranch)
  local remote=$(gbranchremote $curbranch)
  if [ -z "$remote" ]; then
    echo "Not tracking a remote branch; can't open a PR"; return
  fi
  local mainbranch=$(gmainbranch)
  open $github_url/$github_owner/$github_repo/compare/$mainbranch...$curbranch
}
gmyissues() {
  gsetapivalues && gh_api_call "search/issues?q=assignee:$GIT_USERNAME+repo:$github_owner/$github_repo+state:open" | jq '.["items"][] | {number: .["number"], title: .["title"], url: .["html_url"]} + if has("pull_request") then {is: "PULL REQUEST"} else {} end  + if (.["labels"] | any(.["name"] == "epic")) then {is: "EPIC"} else {} end'
}
gmyprsassigned() {
  gh_prs_api_call "assignee:$GIT_USERNAME" | jq '.["items"][] | {number: .["number"], title: .["title"], author: .["user"]["login"], label: [.["labels"][] | .["name"]] | join(", ")}'
}
gmyprscreated() {
  gh_prs_api_call "author:$GIT_USERNAME" | jq '.["items"][] | {number: .["number"], title: .["title"], label: [.["labels"][] | .["name"]] | join(", ")}'
}
alias gmyprs="echo 'ASSIGNED' && gmyprsassigned && echo 'CREATED' && gmyprscreated"
gsquash() {
  local curbranch=$(gcurbranch)
  local mainbranch=$(gmainbranch)
  local branch_parent_commit=$(git merge-base $curbranch $mainbranch)
  if [ -z "$curbranch" ]; then
    echo "No current branch obtained. No squashy."
  elif [[ "$curbranch" == $mainbranch ]]; then
    echo "You are currently on $mainbranch. No squashy."
  elif [ -z "$branch_parent_commit" ]; then
    echo "No branch parent commit found. No squashy."
  else
    commitmsg=''
    if (( $# < 1 )); then
	    curbranchprtitle=$(gcurbranchprinfo | jq -r 'if . | length == 0 then "" else .[0]["title"] end')
	    if [ -z "$curbranchprtitle" ]; then
	      # Get the commit hash for the first commit after the merge-base
	      first_branch_commit=$(git log --format=%H | tr '\n' ',' | grep -Eo "\w+,$branch_parent_commit" | grep -Eo "^[^,]+")
		  # Get the commit message
	  	proposed_title=$(git show "$first_branch_commit" --format="%s" --no-patch)
	    else
	      proposed_title="$curbranchprtitle"
	    fi
      read -q "REPLY?No message specified. Use the following? [$proposed_title]: "
	    echo
	    case "$REPLY" in
        y|Y ) commitmsg="$proposed_title";;
        * ) echo "Need to specify a commit message. No squashy." && return;;
      esac
	  else
	    commitmsg="$(echo $@)"
	  fi
    git reset --soft "$branch_parent_commit"
    git commit -am "$commitmsg"
    #git push -fz
  fi
}
gtagrelease() {
  if [ -z "$1" ]; then
    echo "Need tag as param"
    return
  else
    # coerce to semantic version - eliminates 'v', etc.
	tag=$(echo "$1" | grep -Eo '\d+\.\d+\.\d+')
	if [ -z "$tag" ]; then
	  echo "Tag ($1) is not a valid semantic version"
	  return
	fi
  fi
  git tag -a -m "Release $tag" "v$tag"
  # git push --follow-tags
}
alias greb='git fetch && git rebase'
alias grebmaster='git fetch && git rebase origin/master'
alias grebmain='git fetch && git rebase origin/main'
alias grebabort='git rebase --abort'
alias grebcontinue='git rebase --continue'
alias grebskip='git rebase --skip'
gsnipchanges() {
  local filename=''
  local filepath=''
  local fileext="$1"
  if [ ! -z $2 ]; then
    filename="$2"
  else
    local cleancurbranch=$(gcurbranch | sed 's/\//\-/g')
    filename="$cleancurbranch"
  fi
  if [ -f "$CODESNIP/$filename.$fileext" ]; then
    filename="$filename-$(epoch)"
  fi
  filepath="/tmp/$filename.$fileext"$
  git diff > "$filepath" && snippet "$filepath" && rm -f "$filepath"
}
gpatchsnip() { gsnipchanges 'patch' $@; }
gdiffsnip() { gsnipchanges 'diff' $@; }
gprbuildfail() {
  local pr_num
  if [ -z $1 ]; then
    pr_num=$(gcurbranchprnumber)
  else
    pr_num=$1
  fi
  if [ -z $pr_num ]; then
    echo "PR number was not provided and could not be determined"
    return
  fi
  
  local statuses_url
  local build_url
  local build_id
  local failed_job_data
  local num_failures
  local job_id

  gsetapivalues
  statuses_url=$(curl -s -u "$GIT_USERNAME:$GIT_TOKEN" "$GITHUB_API_URL/repos/$github_owner/$github_repo/pulls/$pr_num" | jq -r '.["statuses_url"]')
  build_url=$(curl -s -u "$GIT_USERNAME:$GIT_TOKEN" $statuses_url | jq -r '[.[] | {state: .state, target_url: .target_url}] | map(select(.state == "failure")) | .[0]["target_url"]')
  build_id=$(echo $build_url | perl -nle '/\/builds\/([0-9]+)/ && print "$1";')
  # ... get list of id, env for failed jobs for the given build
  failed_job_data=$(curl -s "https://api.travis-ci.org/builds/$build_id" | jq '[.["matrix"][] | {id: .id, config: .config, result: .result}] | map(select(.result == 1)) | [.[] | {id: .id, env: .config.env}]')
  # ... get job log output...
  num_failures=$(echo $failed_job_data | jq '. | length')
  if [ $num_failures -eq 1 ]; then
    job_id=$(echo $failed_job_data | jq '.[0] | .id')
    curl -s -L "https://api.travis-ci.org/jobs/$job_id/log"
  else
    echo "Number of failures == $num_failures. This command is set up to handle 1 and only 1."
  fi
}
gnewrfc() {
  if [ -z $1 ]; then
    echo "Please enter a filename for the RFC (w/o extension)"
    return
  fi
  cp ./docs/rfcs/0000-template.md ./docs/rfcs/$1.md
}
retrocomments() {
  if [ -z $1 ]; then
    echo "Need issue #. Exiting..."
    return
  fi
  curl -L -s -H "Authorization: token $GITHUB_MIT_TOKEN" "https://github.mit.edu/api/v3/repos/$GITHUB_MIT_OWNER/retrospectives/issues/$1/comments"
}
retrocollect() {
  if [ -z $1 ]; then
    echo "Need issue #. Exiting..."
    return
  fi
  output=$(retrocomments $1 | python $DEVPATH/sideprojects/retrocollect/collect.py)
  echo $output
}


### Docker functions and aliases
export DOCKPGUSER=postgres
export DOCKPGDBNAME=postgres
export DOCKPGTESTDBNAME=test_postgres
dockenv() { eval "$(docker-machine env $1)" }
alias dockunsetenv="unset DOCKER_TLS_VERIFY; unset DOCKER_CERT_PATH; unset DOCKER_MACHINE_NAME unset DOCKER_HOST;"
alias docksshc='docker-compose run --rm web bash'
alias dockbuild='docker-compose build'
alias dockbuildall='docker-compose build web && dockbuild celery'
alias dockbuildallnb='dockbuildall && docknbbuild'
alias dockstop='docker-compose stop'
alias dockrestart='docker-compose restart'
alias dresweb='docker-compose restart web'
alias dreswatch='docker-compose restart watch'
alias dockpause='docker-compose pause'
alias dockunpause='docker-compose unpause'
alias dockps='docker-compose ps'
alias dockgetdbport="docker-compose ps | grep '_db' | grep -Eo '[^ ]+\s+$' | grep -Eo ':(\d+)' | cut -c 2-"
alias dockup='docker-compose up'
alias dockupd='docker-compose up -d'
alias dockrun='docker-compose run --rm'
alias dockexec='docker-compose exec'
alias dockattachweb='docker attach $(docker-compose ps | grep -Eo "^.*_web_1")'
alias dattachweb=dockattachweb
alias dockwebmanage='docker-compose run --rm web ./manage.py'
alias dockdbcontainer='docker ps --format ''{{.Names}}'' | grep "_db_" | head -n 1'
alias dup=dockup
alias drun=dockrun
alias dockmstop='docker-machine stop'
alias dockmrestart='docker-machine restart'
alias dockstart='docker-machine start'
alias docksshm='docker-machine ssh'
alias dockregen='docker-machine regenerate-certs'
alias dmanage=dockwebmanage
alias dockwebmanagerunning='docker-compose exec web ./manage.py'
alias dmanagerunning='docker-compose exec web ./manage.py'
alias dockwebshell='dockwebmanage shell'
alias dshell=dockwebshell
dockrestartuwsgi() {
  docker-compose exec web bash -c "uwsgi --reload $(awk -F "=" '/pidfile/ {print $2}' uwsgi.ini)"
}
alias dmakemigration='dmanage makemigrations'
dmigrate() { dmanage migrate $@; }
alias dockpipnewreq='docker-compose run web pip-compile requirements.in && docker-compose build web'
alias dlogdebug='sed -i "" "s/DJANGO_LOG_LEVEL=[A-Z]*/DJANGO_LOG_LEVEL=DEBUG/g" .env'
alias dloginfo='sed -i "" "s/DJANGO_LOG_LEVEL=[A-Z]*/DJANGO_LOG_LEVEL=INFO/g" .env'
alias dlogreset=dloglevelinfo
dockdbport() {
	export DOCK_DB_PORT=$(dockgetdbport)
  if [ -z "$1" ] || [ "$1" != '-s' ]; then
	  echo "$DOCK_DB_PORT"
	fi
}
docksetup() {
  local devpath=$1
  local machinename=$2
  if [[ "$devpath" == "." ]]; then
    devpath=$(pwd)
  fi
  if [ $(pwd) != "$devpath" ]; then
    echo "Changing directory to $devpath"
	  cd $devpath
  fi
  if [ $(docker-machine status $machinename) != "Running" ]; then
    docker-machine start $machinename
  fi
  if [ "$DOCKER_MACHINE_NAME" != "$machinename" ]; then
    echo "Setting docker env variables"
	  dockenv $machinename
  fi
  if [[ $(venvcurrent) != *$(pwdtail)* ]]; then
    echo "Setting virtualenv"
  	venv
  fi
}
dockdbport() { docker-compose ps | grep '_db' | perl -nle '/[0-9\.]*:(\d+)/ && print "$1";' }
docknginxport() {
  # hacky af, bruh
  cat docker-compose.yml | grep 'nginx:' -A 15 | grep 'ports:' -A 1 | head -2 | tail -1 | perl -nle '/(\d+)\"/ && print "$1";'
}
dockwebport() {
  cat docker-compose.yml | yq '.["services"]["web"]["ports"][0]' | perl -nle '/([0-9]+):/ && print "$1"';
}
dockwebservice() {
  docker-compose run --rm --service-ports web ./manage.py runserver 0.0.0.0:$(dockwebport)
}
alias dockrunserviceweb=dockwebservice
openrunning() {
  echo "Needs to be reimplemented - maybe use .env variables"
}
dockrmruncontainers() {
  docker rm $(docker ps -a | grep "_run_" | perl -nle '/^(\w+)/ && print "$1";')
}
# Docker postgres db backup/restore/etc.
dockdbconnect() { 
  local dbname="${1:-postgres}" 
  psql -h 127.0.0.1 -p $(dockdbport) -U "$dbname"
}
dockdbbackup() {
  local repo=$(echo ${PWD##*/})
  local timestamp=$(date +%s)
  local backup_filename="$repo-$timestamp.sql"
  local container_backup_dir="/tmp"
  local container_backup_path="$container_backup_dir/$backup_filename"
  local host_backup_dest="$DBBACKUPDIR/$backup_filename"
  
  docker-compose exec db pg_dump --username=$DOCKPGUSER --dbname=$DOCKPGDBNAME --file $container_backup_path
  docker cp "$(dockdbcontainer):$container_backup_path" $host_backup_dest
  echo $host_backup_dest
}
dockdbrestore() {
  local repo=$(echo ${PWD##*/})
  local dbcontainer=$(docker ps --format '{{.Names}}' | grep "_db_")
  local container_backup_dir="/tmp"
  
  local backup_filename=$1
  if [ -z $backup_filename ]; then
    local backup_options=$(ls -t $DBBACKUPDIR | grep -E "^$repo-.*")
    local first_option=$(echo $backup_options | head -n 1)
    if [ -z $first_option ]; then
      echo "No backups exist in the backup directory ($DBBACKUPDIR) for this repo ($repo)"
      return
    fi
    local other_options=$(echo $backup_options | tail -n +2)
    read -q "REPLY?No backup filename specified. Use the following? [$first_option]: "
    echo
    case "$REPLY" in
      y|Y ) backup_filename="$first_option";;
      * ) [[ ! -z $other_options ]] && echo "Other backup files:" && echo $other_options; return;;
    esac
  fi
  
  local host_backup_path="$DBBACKUPDIR/$backup_filename"
  if [ ! -f $host_backup_path ]; then
    echo "Backup file does not exist at $host_backup_path"
    return
  fi  
  local container_backup_path="$container_backup_dir/$backup_filename"
  docker cp $host_backup_path "$(dockdbcontainer):$container_backup_path"

  local backup_db_name=$DOCKPGDBNAME"_bak"
  docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "ALTER DATABASE $DOCKPGDBNAME RENAME TO $backup_db_name" && \
    docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "CREATE DATABASE $DOCKPGDBNAME" && \
    docker-compose exec db psql -d $DOCKPGDBNAME -U $DOCKPGUSER -f $container_backup_path && \
    docker-compose exec db psql -d $DOCKPGDBNAME -U $DOCKPGUSER -c "DROP DATABASE $backup_db_name" && \
    docker-compose exec db rm -f $container_backup_path
}
dockdbexists() {
  docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -tAc "SELECT 1 FROM pg_database WHERE datname='$1'"
}
dockdbswapname() {
  local backup_db_name=$DOCKPGDBNAME"_bak"
  local second_backup_db_name=$DOCKPGDBNAME"_bak_2"
  
  local second_backup_exists=$(dockdbexists "$second_backup_db_name")
  if [ $second_backup_exists -eq 1 ]; then
    # Back up the backup
    docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "DROP DATABASE $second_backup_db_name"
    docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "ALTER DATABASE $backup_db_name RENAME TO $second_backup_db_name"
  fi
  docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "ALTER DATABASE $DOCKPGDBNAME RENAME TO $backup_db_name" && \
    docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "CREATE DATABASE $DOCKPGDBNAME" && \
    docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "\\l"
}
dockdbunswapname() {
  local backup_db_name=$DOCKPGDBNAME"_bak"
  local second_backup_db_name=$DOCKPGDBNAME"_bak_2"
  
  local backup_exists=$(dockdbexists "$backup_db_name")
  if [ $backup_exists -ne 1 ]; then
    echo "Backup database ($backup_db_name) does not exist. Cannot swap. Exiting..."
    return
  fi
  
  docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "DROP DATABASE IF EXISTS $second_backup_db_name"
  docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "ALTER DATABASE $DOCKPGDBNAME RENAME TO $second_backup_db_name"
  docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "ALTER DATABASE $backup_db_name RENAME TO $DOCKPGDBNAME" && \
    docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "DROP DATABASE IF EXISTS $second_backup_db_name" && \
    docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "\\l"   
}
dockdbblank() {
  docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "DROP DATABASE $DOCKPGDBNAME" && \
    docker-compose exec db psql -d $DOCKPGTESTDBNAME -U $DOCKPGUSER -c "CREATE DATABASE $DOCKPGDBNAME"
}

# Docker jupyter notebook stuff
alias docknbbuild="docker-compose -f docker-compose-notebook.yml build"
alias dockbuildnb=docknbbuild
alias docknbrun="docker-compose -f docker-compose-notebook.yml run --rm --service-ports notebook"
alias docknbrunningcontainer="docker ps --format '{{.Names}}' | grep \"_notebook_run_\""
docknbrunningtokenqs() {
  local NB_PORT="${1:-8080}"
  local running_container=$(docknbrunningcontainer)
  if [ -z $running_container ]; then
    echo "Notebook container doesn't appear to be running"
    return
  fi
  docker logs $running_container 2>&1 | grep -E "http://(.*):"$NB_PORT"[^ ]+\w" | tail -1 | grep -Eo "\?(\w|\d|=)*"
}
docknbrooturl() {
  local APP_HOST="${1:-127.0.0.1}"
  local NB_PORT="8080"
  local nb_token_param=$(docknbrunningtokenqs $NB_PORT)
  local nb_server_url=http://"$APP_HOST":"$NB_PORT"
  echo "$nb_server_url/$nb_token_param"
}
docknbrooturlcopy() {
  docknbrooturl $1 | pbcopy
}
docknbopen() {
  local APP_HOST="${1:-127.0.0.1}" 
  local NB_PORT="8080"
  local nb_token_param=$(docknbrunningtokenqs $NB_PORT)
  local nb_server_url=http://"$APP_HOST":"$NB_PORT"
  
  local nb_paths=$(find . -name "*.ipynb" | grep -v "checkpoint")
  local lines=$(echo $nb_paths | wc -l | tr -d '[:space:]')
  
  local full_nb_url=""
  if [[ $lines == "1" ]]; then
    # Only one .ipynb file exists - open the server at the path of that file
    local nb_path=$(echo $nb_paths | head)
    nb_path=${nb_path:2}
    full_nb_url="$nb_server_url"/notebooks/"$nb_path""$nb_token_param"
  elif [[ $lines == "0" ]]; then
    # No .ipynb files - open the server at the root
    full_nb_url=$nb_server_url
  else
    # Multiple .ipynb files - open the server at the folder containing the first
    local nb_path=$(echo $nb_paths | head)
    local notebook_dir=$(dirname $nb_path)
    notebook_dir=${notebook_dir:2}
    full_nb_url="$nb_server_url"/tree/"$notebook_dir""$nb_token_param"
  fi
  open $full_nb_url
}
docknbstoprunning() {
  local runningContainer=$(docknbrunningcontainer)
  if [ ! -z $runningContainer ]; then
    echo "Stopping and removing currently running container ($runningContainer)..."
    docker stop $runningContainer && docker -v rm $runningContainer
  fi
}
docknbrunopen() {
  docknbstoprunning
  docker-compose -f docker-compose-notebook.yml run --rm --service-ports -d notebook
  
  local sleepTime=2
  local totalBeats=8
  local idx=0
  
  sleep $sleepTime
  local runningTokenQs=$(docknbrunningtokenqs)
  while [ -z $runningTokenQs -a $idx -ne $totalBeats ]; do
    echo "NB Server not yet running. Retrying..."
    runningTokenQs=$(docknbrunningtokenqs)
    idx=$(($idx + 1))
    sleep $sleepTime
  done
  
  if [ -z $runningTokenQs ]; then
    echo "Couldn't confirm in the logs that the NB server is running. Exiting..."
    return
  fi
  docknbopen $@
}

### More custom commands for Docker-ized apps
alias lintjs='docker-compose run --rm watch npm run-script lint'
alias lintsass='docker-compose run --rm watch npm run-script scss_lint'
alias lint='lintjs && lintsass'
alias nfmt='npm run fmt'
alias jsfmt=nfmt
alias pyfmt='docker-compose run --rm web black .'
alias pysort='docker-compose run --rm web bash -c "isort ."'
lintpy() {
  local has_pytest_plugin=$(cat test_requirements.txt | grep "pytest-pylint")
  if [[ -z $has_pytest_plugin ]]; then
    echohighlight "Running pylint directly..."
    docker-compose run --rm web bash -c "pylint ./**/*.py"
  else
    echohighlight "Running pylint plugin via py.test..."
    docker-compose run --rm web pytest --pylint -m pylint
  fi
}
### OLD VERSION
alias testpytestnolint='docker-compose run --rm web pytest --no-pylint'
alias testpytest='docker-compose run --rm web pytest'
testpy() {
  if [[ -f "./tox.ini" ]]; then
    echohighlight "Running tox..."
    testpytox $@
  else
    echohighlight "Running pytest..."
    testpytest $@
  fi
}
testpysimple () {
  testpy --no-pylint --no-cov $@
}
alias testpynolint=testpysimple
testpypush() {
  pyfmt
  testpy && gpsh -f
}
alias toxkillpyfmt='sed -i "" -e "s/black\ --check/#\ black\ --check/g" tox.ini'
alias toxrestorepyfmt='sed -i "" -e "s/#\ black\ --check/black\ --check/g" tox.ini'
alias testcfgminimal='/bin/cp -f pytest_minimal.ini pytest.ini'
alias testcfgrevert='git checkout origin/master pytest.ini'
testpymin() {
  local keepmin=''
  if [ ! -z "$1" ] && [ "$1" = '--keepmin' ]; then
    keepmin="true"; shift
  fi
  testcfgminimal && docker-compose run --rm web tox $@;
  if [ -z "$keepmin" ]; then
  	testcfgrevert
  fi
}
alias testpyminkeep='testpymin --keepmin'
testjs() {
  local cmd=""
  if [[ -f "./js_test.sh" ]]; then
    cmd="./js_test.sh"
  elif [[ -f "./scripts/test/js_test.sh" ]]; then
    cmd="./scripts/test/js_test.sh"
  else
    cmd="npm run test"
    if [ ! -z "$1" ]; then
      cmd="$cmd -- $@"
    fi
  fi
  echohighlight "$cmd"
  docker-compose run --rm watch bash -c "$cmd"
}
alias testjsroot="docker-compose run --rm watch ./js_test.sh"
alias dwatchbash='docker-compose run --rm watch bash'
alias dwebbash='docker-compose run --rm web bash'
alias flowjs='npm run-script flow'
dockdbrun() {
  local runcmd=$1; shift
  local db="postgres"
  local dbport=$(dockdbport)
  
  if [ -z $dbport ]; then
    echo "No DB port detected. Is the 'db' service running?"
  else
    psql -h 127.0.0.1 -p $(dockdbport) -U postgres --dbname=$db -c $runcmd $@
  fi
}
alias dockdbrunquery=dockdbrun
alias dbmigrationquery="dbrun 'SELECT * FROM django_migrations;'"
migrationdiff() {
  local mergebase
  local branch1=$(gcurbranch)
  local branch2=$(gmainbranch)
  if [ ! -z "$2" ]; then
    branch2=$2
  fi
  if [ ! -z "$1" ]; then
    branch1=$1
  fi
  mergebase=$(git merge-base $branch1 $branch2)
  git diff --name-only "$mergebase" | grep "migrations/"
}

### Docker edX devstack commands
alias dedxcustomimagebuild="docker build $CUSTOM_DEVSTACK_PATH -t $CUSTOM_DEVSTACK_IMG_NAME_PY3 --build-arg BASE_IMG=$CUSTOM_DEVSTACK_BASE_IMG --no-cache --rm --force-rm"
function getservicefromargs() {
  # These docker-compose helper functions below assume that flags can be passed in along with
  # a single service name. If a string is found that isn't a flag (i.e.: doesn't start with '-'),
  # it's assumed that is the service name.
  for arg in "$@"; do
    if  [[ $arg != -* ]]; then
        echo $arg; return
    fi
  done
}
function dedxup() {
  local servicename=$(getservicefromargs $@)
  local compose_file_args=()
  local flags=()
  # Run as detached by default
  flags+=('-d')
  
  # Add custom compose file(s) to docker-compose params if it's set and the file exists
  if [ ! -z $USE_CUSTOM_DEVSTACK ] || [ $USE_CUSTOM_DEVSTACK -eq 1 ]; then
    compose_file_args+=( '-f' "$CUSTOM_DEVSTACK_PATH/$DEFAULT_CUSTOM_DEVSTACK_COMPOSE_FILE" )
    if [ ! -z $CUSTOM_DEVSTACK_COMPOSE_FILE ]; then
      compose_file_args+=( '-f' "$CUSTOM_DEVSTACK_PATH/$CUSTOM_DEVSTACK_COMPOSE_FILE" )
    fi
    for compose_file_arg in "${compose_file_args[@]}"
    do
      if [ $compose_file_arg != '-f' ]; then
        echo -e "Using additional compose file (\033[1;92m$compose_file_arg\e[0m) ..."
      fi
    done
    echo ''
  fi
  
  # Change docker-compose flags according to the arguments passed into this function
  for arg in "$@"; do
    # Running docker-compose in detached mode ('-d') by default. If '--attach' is passed in,
    # remove that parameter
    if  [[ $arg == "--attach" ]]; then
      flags=( "${flags[@]/-d}" )
    # All other flags should be added to the command exactly as they were passed into this function
    elif [[ $arg == -* ]]; then
      flags+=( $arg )
    fi
  done
  
  docker-compose -f docker-compose.yml -f docker-compose-host.yml ${compose_file_args[@]} up ${flags[@]} $servicename
}
function dedxlog() { make $1-logs }
function dedxlograw() { docker logs "edx.devstack.$1" -f --tail=500 }
function dedxattach() { make $1-attach }
function dedxuplog() {
  local servicename=$(getservicefromargs $@)
  dedxup $@
  
  # Wait until logs exist...
  local idx=0
  local lognoteof=$(docker logs "edx.devstack.$servicename" | tail -n 1 | grep -v 'Error grabbing logs: EOF')
  while [ -z $lognoteof -a $idx -ne 5 ]; do
    echo "Log not created yet. Retrying..."
    lognoteof=$(docker logs "edx.devstack.$servicename" | tail -n 1 | grep -v 'Error grabbing logs: EOF')
    idx=$(($idx + 1))
    sleep 2
  done
  
  make $servicename-logs
}
function dedxupattach() { local servicename=$(getservicefromargs $@); dedxup $@; make $servicename-attach }
function dedxserverrestart() { make $1-restart }
function dedxbashraw() {
  docker exec -it "edx.devstack.$1" env TERM=$TERM bash
}
function dedxbash() {
  make $1-shell
}
function dedxrun() {
  local servicename="$1"; shift
  docker exec -it "edx.devstack.$servicename" env TERM=$TERM bash -c "source /edx/app/edxapp/edxapp_env && cd /edx/app/edxapp/edx-platform; cd /edx/app/edxapp/edx-platform; $@"
}
function dedxdshell() {
  local servicename=$1; shift
  local appname=$servicename
  if [[ "$servicename" == "studio" ]]; then
    appname="cms"
  elif [[ "$servicename" == "cms" ]]; then
    servicename="studio"
  fi
  dedxrun $servicename "python ./manage.py $appname --settings=devstack_docker shell $@" 
}
dedxfullstatic() {
  local apps=( lms studio )
  for app in "${apps[@]}"; do
    docker-compose exec $app bash -c 'source /edx/app/edxapp/edxapp_env && cd /edx/app/edxapp/edx-platform && paver update_assets --settings devstack_docker'
  done
}
function dedxprereq() { 
  local apps=( lms studio )
  if [ ! -z $1 ]; then
    apps=( $1 )
  fi
  for app in "${apps[@]}"; do
    docker-compose exec $app bash -c 'source /edx/app/edxapp/edxapp_env && cd /edx/app/edxapp/edx-platform && NO_PYTHON_UNINSTALL=1 paver install_prereqs'
  done
}
function dedxprereqforce() { 
  local apps=( lms studio )
  if [ ! -z $1 ]; then
    apps=( $1 )
  fi
  for app in "${apps[@]}"; do
    docker-compose exec $app bash -c 'source /edx/app/edxapp/edxapp_env && cd /edx/app/edxapp/edx-platform && unset NO_PYTHON_UNINSTALL && paver install_prereqs'
  done
}
function dedxdbupdate() {
  local app=${1:-"lms"}
  dedxrun $app 'NO_PREREQ_INSTALL=1 paver update_db --settings devstack_docker'
}
function dedxjsonconf() {
  local servicename=$1
  local filenamebase=$servicename
  local conftype="env"
  if [ ! -z $1 ]; then
    if [[ "$1" == "studio" ]]; then
      filenamebase="cms"
    elif [[ "$1" == "cms" ]]; then
      servicename="studio"
    else
      servicename="$1"
      filenamebase="$1"
    fi
  fi
  if [ ! -z $2 ]; then
    conftype="$2"
  fi
  docker exec -it "edx.devstack.$servicename" /usr/bin/env bash -c "vim /edx/app/edxapp/$filenamebase.$conftype.json"
}
alias dedxlms="dedxup lms"
alias dedxstudio="dedxup studio"
alias dedxlmslog="make lms-logs"
alias dedxstudiolog="make studio-logs"
function dedxlmsrun() { dedxrun lms $@ }
function dedxstudiorun() { dedxrun studio $@ }
function dedxlmstestpy() {
  dedxlmsrun "pytest $@ --disable-pytest-warnings"
}
alias dedxlmsdbupdate="dedxdbupdate lms"
alias dedxlmssamlfix="dedxlmsrun 'pip uninstall python-saml dm.xmlsec.binding -y && pip install -r requirements/edx/post.txt'"
alias dedxlmsreleasechange="dedxlmsdbupdate && make lms-static"

### Node stuff
alias webpack="./webpack_dev_server.sh"
alias webpackinstall="./webpack_dev_server.sh --install"
alias webpackinstallsass="npm rebuild node-sass --force && webpackinstall"
alias npmsass="npm rebuild node-sass --force"

# EDX
export DOCKER_COMPOSE_FILES="-f docker-compose.yml -f docker-compose-host.yml"
export DEVSTACK_WORKSPACE="/Users/gavin/dev/edx_devstack_docker"
# Vagrant VM legacy commands
alias edxfstart='cd $EDX_FICUS_PATH && vup && vssh'
alias edxfstartfresh='cd $EDX_FICUS_PATH && vhalt && vup && vssh'
alias edxgstart='cd $EDX_GINKGO_PATH && vup && vssh'
alias edxgstartfresh='cd $EDX_GINKGO_PATH && vhalt && vup && vssh'

# MICROMASTERS
export MM_MACHINE_NAME='mm'
alias mmenv="dockenv $MM_MACHINE_NAME"
alias mmstartmachine="docker-machine start $MM_MACHINE_NAME"
alias mmsetup='mmstartmachine; mmenv'
alias mmrestart='dockrestart mm'
alias mm="docksetup $MM_PATH $MM_MACHINE_NAME"
alias mmstart='mm && docker-compose up'
alias mmstartdb='mm && docker-compose up db'
alias mmstartdbelastic='mm && docker-compose up db elastic'
alias mmstartnonweb='mm && docker-compose up db elastic celery redis sftp'
alias mmstartweb='mm && docker-compose run --service-ports web'
alias mmstartwebnginx='mm && docker-compose up nginx web'
alias mmwebpdb='docker-compose run --service-ports web ./manage.py runserver 0.0.0.0:8077'
alias mmweb=mmstartweb
alias mmwebnginx=mmstartwebnginx
alias mmdbelastic=mmstartdbelastic
alias mmnonweb=mmstartnonweb
mmmanage() {
	mm && docker-compose run web ./manage.py $@
}
alias mmmakemigration='mmmanage makemigrations'
mmshowmigrations() { mmmanage showmigrations $1; }
mmmigrate() { mmmanage migrate $@; }
alias mmip='docker-machine ip '"$MM_MACHINE_NAME"
alias mmstartserver='mmenv && docker-compose run --service-ports web ./manage.py runserver 0.0.0.0:8079'
alias mmwebpack='mm && webpack'
alias mmwebpackinstall='mm && webpackinstall'
alias mmshell='mm && docker-compose run web ./manage.py shell'
alias mmindex='mm && docker-compose run web ./manage.py recreate_index'
mmseed() {
  mm && docker-compose run web ./manage.py seed_db --staff-user=${1:-"staff"}
}
alias mmunseed='mm && docker-compose run web ./manage.py unseed_db'
mmsearchindex() {
  if [ ! -z $1 ]; then
    esquery="q=$1"
  else
    esquery=""
  fi
  docker-compose run web curl "http://elastic:9200/micromasters/_search?$esquery" | jq '.'
}
mmfullstaticbuild() {
  local debug=$(cat ./docker-compose.yml | grep -Eo "DEBUG: 'True'")
  if [ ! -z "$debug" ]; then
    git apply $CODESNIP/patches/docker_debug_false.patch
  fi
  node node_modules/webpack/bin/webpack.js --config webpack.config.prod.js --bail &&
    docker-compose run web ./manage.py collectstatic --no-input &&
    echo "\nRESTART THE MM SERVER"
}
mmcleanstaticbuild() {
  local notdebug=$(cat ./docker-compose.yml | grep -Eo "DEBUG: 'False'")
  if [ ! -z "$notdebug" ]; then
    git checkout -- ./docker-compose.yml
  fi
  docker-compose run web bash -c "rm -rf ./staticfiles"
}
mmdb() { 
  mmenv && dbconnect
}
mmdbrun() {
  mmenv && dbrun $@
}
mmdbnotfilledout() {
  mmdbrun "update profiles_profile set filled_out = 'f' where edx_name = 'staff';"
}
mmdbfilledout() {
  mmdbrun "update profiles_profile set filled_out = 't' where edx_name = 'staff';"
}
alias mmtest='./test_suite.sh'
alias mmtestfull='docker-compose run watch npm test && docker-compose run watch npm run-script lint'
alias mmtestsuite='. ./test_suite.sh'
alias mmtoxenv='. .tox/py35/bin/activate'
alias mmdjangodebug='cp $CODESNIP/settingsfiles/.env_django_debug ~/dev/micromasters/.env'
alias mmdjangowarning='cp $CODESNIP/settingsfiles/.env_django_warning ~/dev/micromasters/.env'
alias mmnb='mm && dockdbport -s && jupyter notebook micromasters.ipynb --log-level=ERROR' # --notebook-dir=".ipynb"
mmsetloglevel() {
  sed -i -e "s/MICROMASTERS_LOG_LEVEL=$1/MICROMASTERS_LOG_LEVEL=$2/g" .env
  sed -i -e "s/DJANGO_LOG_LEVEL=$1/DJANGO_LOG_LEVEL=$2/g" .env
}
alias mmsetdebug="mmsetloglevel WARNING DEBUG"
alias mmsetwarning="mmsetloglevel DEBUG WARNING"

# BOOTCAMP
export BOOTCAMP_MACHINE_NAME='bootcamp'
alias bootenv="dockenv $BOOTCAMP_MACHINE_NAME"
alias bootstartmachine="docker-machine start $BOOTCAMP_MACHINE_NAME"
alias bootsetup='bootstartmachine; bootenv'
alias bootrestart="dockrestart $BOOTCAMP_MACHINE_NAME"
alias bootcamp="docksetup $BOOTCAMP_PATH $BOOTCAMP_MACHINE_NAME"
alias bootstart='bootcamp && docker-compose up'
alias bootstartdec='bootcamp && docker-compose up db elastic celery'
alias bcamp=bootcamp
alias bstart=bootstart
bootmanage() {
	bootcamp && docker-compose run web ./manage.py $@
}
alias bootshell='bootmanage shell'
alias bootnb="startnb $BOOTCAMP_MACHINE_NAME"
alias boottestjs='./scripts/test/js_test.sh'
bootdb() { 
  bootenv && dbconnect
}
bootdbrun() {
  bootenv && dbrun $@
}

# REDDIT/REDDIT-CONFIG
alias redditstart="pushd $REDDIT_CONF_PATH; vagrant up; popd"
alias redditrun=redditstart
alias redditrebuild="pushd $REDDIT_CONF_PATH; vagrant reload && vagrant provision; popd"
alias redditrestart="pushd $REDDIT_CONF_PATH; vagrant ssh -c 'sudo reddit-restart'; popd"
alias redditerrorlogtail="vagrant ssh -c \"sudo tail -f /var/log/upstart/reddit-paster.log\""
alias redditlasterror="vagrant ssh -c \"sudo tac /var/log/upstart/reddit-paster.log | grep -m 1 'Debug at:' | grep -Eo 'http[^\s]*'\""
alias redditserverstatus='curl -s --head "http://reddit.local/" --connect-timeout 6 | head -n 1'
alias redditrunning='redditserverstatus | grep -o "200 OK"'
redditstatus() {
  pushd $REDDIT_CONF_PATH
  local vmrunning=$(vagrant status default | grep -Eo 'default\s+running\s\(')
  popd
  if [ -z $vmrunning ]; then
    echo "Reddit Vagrant VM is not running"; return
  fi
  local serverstatus=$(redditserverstatus)
  echo "Reddit server status: $serverstatus"
}
alias rstatus=redditstatus
alias rbuild=redditrebuild

# SALTSTACK LOCAL STUFF
export SALTSTACK_SANDBOX_VM_PATH="$SALTSTACK_SANDBOX_PATH/virtual-machines"
alias cdsaltsandvagrant="cd $SALTSTACK_SANDBOX_VM_PATH"
alias saltsandup="cdsaltsandvagrant && vagrant up"

# LIBS
export MLIBSPATH="$DEVPATH/sideprojects/mlibs"
alias cdlibs="cd $MLIBSPATH"
alias libs="cdlibs && pvenv"
alias libsrunpy="python run.py runserver"
alias libsrunjs="npm start"

# Pythonz setup
[[ -s $HOME/.pythonz/etc/bashrc ]] && source $HOME/.pythonz/etc/bashrc
